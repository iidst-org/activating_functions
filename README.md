# Activation Functions Visualization

This project visualizes common activation functions used in neural networks. The script generates plots for the following activation functions:

- **Sigmoid**
- **Tanh**
- **ReLU (Rectified Linear Unit)**
- **Leaky ReLU**

## ðŸ“Œ Requirements

Ensure you have Python installed along with the required libraries:

```bash
pip install numpy matplotlib
